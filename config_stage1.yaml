# Configuration for stage1_train.py
# Stage 1: Binding classification training

# Model Version
# -------------
version: "v0"  # Used for output directory naming

# Input Paths
# -----------
input:
  # Ligand data CSV (must have: smiles, source, selectivity, target)
  ligand_csv: "data/ligands/smiles_binding_pdb_decoy.csv"
  
  # Pre-computed embeddings
  ligand_features: "data/ligand_features_cache/ligand_features_unimol.pkl"
  pocket_embeddings: "data/pocket_embeddings_cache/pocket_embeddings_unimol_cutoff8A.pkl"

# Output Paths
# ------------
output:
  # Checkpoint directory (version will be appended)
  checkpoint_dir: "models"
  
  # Results directory (version will be appended)
  results_dir: "models/v0/results"
  
  # Checkpoint filename (single stage)
  checkpoint_name: "stage1_best.pt"
  
  # Checkpoint filenames (three stage)
  checkpoint_name_stage1a: "stage1a_best.pt"
  checkpoint_name_stage1b: "stage1b_best.pt"
  
  # Training history filename
  history_name: "stage1_best_history.json"
  history_name_stage1a: "stage1a_best_history.json"
  history_name_stage1b: "stage1b_best_history.json"

# Training Hyperparameters
# -------------------------
training:
  # Dataset configuration
  stage: "binding"  # binding, selectivity, or combined
  
  # Train/validation split
  val_split: 0.2    # Fraction for validation (0.2 = 80/20 split)
  stratify: true    # Stratify by source+label
  
  # Optimization
  epochs: 50
  batch_size: 64
  learning_rate: 3.0e-4
  weight_decay: 1.0e-4
  
  # Reproducibility
  seed: 42
  
  # Device
  device: "auto"  # "auto", "cuda", "cpu"

# Evaluation
# ----------
evaluation:
  # Generate predictions and metrics for both train and val
  save_train_results: true
  save_val_results: true
  
  # Generate confusion matrices per source
  per_source_confusion: true
  sources:
    - "DECOY"
    - "PDB"
  
  # Generate training curves
  plot_training_curves: true

# Three-Stage Pipeline (disabled)
# --------------------------------
three_stage:
  enabled: false


# Metric Learning (optional)
# --------------------------
# Adds a hard-batch triplet loss on PDB examples to push PGK1 / PGK2
# embeddings apart in a 64-dim L2-normalised projection space.
metric_learning:
  enabled: true
  branch: "pre_film" 
  weight: 0.5       # Relative weight of triplet loss vs. BCE loss
  proj_dim: 64      # Output dimension of MetricProjector (256 → 128 → proj_dim)
  margin: 0.3       # Triplet margin (passed to hard_batch_triplet_loss)
